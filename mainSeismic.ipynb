{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train Glow on CIFAR-10.\n",
    "\n",
    "Train script adapted from: https://github.com/kuangliu/pytorch-cifar/\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import util\n",
    "\n",
    "from models import Glow\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64 # type=int# help='Batch size per GPU')\n",
    "benchmark = True # help='Turn on CUDNN benchmarking')\n",
    "gpu_ids=[0]# type=eval# help='IDs of GPUs to use')\n",
    "lr=1e-3# type=float# help='Learning rate')\n",
    "max_grad_norm=-1.# help='Max gradient norm for clipping')\n",
    "num_channels=512# type=int# help='Number of channels in hidden layers')\n",
    "num_levels=3# type=int# help='Number of levels in the Glow model')\n",
    "num_steps=32# type=int# help='Number of steps of flow in each level')\n",
    "num_epochs=100# type=int# help='Number of epochs to train')\n",
    "num_samples=64# type=int# help='Number of samples at test time')\n",
    "num_workers=8# type=int# help='Number of data loader threads')\n",
    "resume=False# help='Resume from checkpoint')\n",
    "seed=0# help='Random seed for reproducibility')\n",
    "warm_up=500000# type=int# help='Number of steps for lr warm-up')\n",
    "\n",
    "best_loss = 0\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def train(epoch, net, trainloader, device, optimizer, scheduler, loss_fn, max_grad_norm):\n",
    "    global global_step\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    loss_meter = util.AverageMeter()\n",
    "    with tqdm(total=len(trainloader.dataset)) as progress_bar:\n",
    "        for x, _ in trainloader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            z, sldj = net(x, reverse=False)\n",
    "            loss = loss_fn(z, sldj)\n",
    "            loss_meter.update(loss.item(), x.size(0))\n",
    "            loss.backward()\n",
    "            if max_grad_norm > 0:\n",
    "                util.clip_grad_norm(optimizer, max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step(global_step)\n",
    "\n",
    "            progress_bar.set_postfix(nll=loss_meter.avg,\n",
    "                                     bpd=util.bits_per_dim(x, loss_meter.avg),\n",
    "                                     lr=optimizer.param_groups[0]['lr'])\n",
    "            progress_bar.update(x.size(0))\n",
    "            global_step += x.size(0)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(net, batch_size, device):\n",
    "    \"\"\"Sample from RealNVP model.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.DataParallel): The RealNVP model wrapped in DataParallel.\n",
    "        batch_size (int): Number of samples to generate.\n",
    "        device (torch.device): Device to use.\n",
    "    \"\"\"\n",
    "    z = torch.randn((batch_size, 3, 32, 32), dtype=torch.float32, device=device)\n",
    "    x, _ = net(z, reverse=True)\n",
    "    x = torch.sigmoid(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up main device and scale batch size\n",
    "device = 'cuda' if torch.cuda.is_available() and gpu_ids else 'cpu'\n",
    "batch_size *= max(1, len(gpu_ids))\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# No normalization applied, since Glow expects inputs in (0, 1)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"D:\\_0Luciano\\_0PHD\\datasets\"\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=root, train=True, download=True, transform=transform_train)\n",
    "trainloader = data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=root, train=False, download=True, transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "i=11\n",
    "\n",
    "tensorImg = trainset[i][0]\n",
    "numpyImg = tensorImg.numpy()[0]\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1, 2, 1); plt.imshow(numpyImg);  plt.axis('off')\n",
    "plt.title(trainset[i][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=iter(trainloader)\n",
    "real_batch = next(iter(it))\n",
    "plt.figure(figsize=(15,15))\n",
    "print(real_batch[0].size())\n",
    "plt.imshow(np.transpose(utils.make_grid(real_batch[0][:64], padding=2, normalize=True).cpu(),(1,2,0)),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Samples from the CIFAR10 Dataset');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "print('Building model..')\n",
    "net = Glow(num_channels=num_channels,\n",
    "            num_levels=num_levels,\n",
    "            num_steps=num_steps)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net, gpu_ids)\n",
    "    cudnn.benchmark = benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('Resuming from checkpoint at ckpts/best.pth.tar...')\n",
    "    assert os.path.isdir('ckpts'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('ckpts/best.pth.tar')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    global best_loss\n",
    "    global global_step\n",
    "    best_loss = checkpoint['test_loss']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    global_step = start_epoch * len(trainset)\n",
    "\n",
    "loss_fn = util.NLLLoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "scheduler = sched.LambdaLR(optimizer, lambda s: min(1., s / warm_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(epoch, net, testloader, device, loss_fn, num_samples):\n",
    "    global best_loss\n",
    "    net.eval()\n",
    "    loss_meter = util.AverageMeter()\n",
    "    with tqdm(total=len(testloader.dataset)) as progress_bar:\n",
    "        for x, _ in testloader:\n",
    "            x = x.to(device)\n",
    "            z, sldj = net(x, reverse=False)\n",
    "            loss = loss_fn(z, sldj)\n",
    "            loss_meter.update(loss.item(), x.size(0))\n",
    "            progress_bar.set_postfix(nll=loss_meter.avg,\n",
    "                                     bpd=util.bits_per_dim(x, loss_meter.avg))\n",
    "            progress_bar.update(x.size(0))\n",
    "\n",
    "    # Save checkpoint\n",
    "    if loss_meter.avg < best_loss:\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'test_loss': loss_meter.avg,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        os.makedirs('ckpts', exist_ok=True)\n",
    "        torch.save(state, 'ckpts/best.pth.tar')\n",
    "        best_loss = loss_meter.avg\n",
    "\n",
    "    # Save samples and data\n",
    "    images = sample(net, num_samples, device)\n",
    "    os.makedirs('samples', exist_ok=True)\n",
    "    images_concat = torchvision.utils.make_grid(images, nrow=int(num_samples ** 0.5), padding=2, pad_value=255)\n",
    "    torchvision.utils.save_image(images_concat, 'samples/epoch_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "    train(epoch, net, trainloader, device, optimizer, scheduler,\n",
    "            loss_fn, max_grad_norm)\n",
    "    test(epoch, net, testloader, device, loss_fn, num_samples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
